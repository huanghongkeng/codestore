1.统计每个word出现的频率，只针对words是一个list
collections.Counter(words).most_common(vocabulary_size - 1)

输入words格式：words = ['I','am','worker']
输出格式：[('I', 1), ('am', 1), ('worker', 1)]



2.文档按字母统计
from keras.preprocessing.text import Tokenizer
texts = data
tokenizer = Tokenizer(char_level=True) # 字向量
tokenizer.fit_on_texts(texts)
word_index = tokenizer.word_index
sequences = tokenizer.texts_to_sequences(data)

输入格式：data为['/103886/','/v2/app_config?device_id=869247036964390']
输出格式：[[1, 18, 10, 22, 34, 34, 30, 1],[1, 18, 10, 22, 34, 34, 30, 1]]
'/103886/'根据word_index索引成[1, 18, 10, 22, 34, 34, 30, 1]